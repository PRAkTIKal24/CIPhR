name: CIPhR Daily Research Ingestion (Hybrid)

# NOTE: This workflow requires the following secrets to be set:
# - PROD_BOT_KEY: SSH key for pushing to repository
# - GEMINI_API_KEY: Google Gemini API key for LLM analysis
# - MM_WEBHOOK_URL: Mattermost incoming webhook URL for ML4DM notifications

on:
  schedule:
    # Runs every day at 00:00 UTC
    - cron: '0 0 * * *'
  workflow_dispatch: # Allows manual triggering

jobs:
  collect_data:
    runs-on: ubuntu-latest
    outputs:
      papers-found: ${{ steps.data-collection.outputs.papers-found }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        ssh-key: ${{secrets.PROD_BOT_KEY}}

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install uv and dependencies
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        export PATH="$HOME/.local/bin:$PATH"
        uv venv
        source .venv/bin/activate
        uv pip install -e .

    - name: Run Data Collection
      id: data-collection
      run: |
        cd ${{ github.workspace }}
        uv run ciphr-hybrid --mode collect --max_results 5 --output_filename hepex.md --tags hep-ex --verbose
        
        # Set output based on whether papers_data.json was created and has content
        if [ -f "output/papers_data.json" ]; then
          PAPER_COUNT=$(python3 -c "import json; data=json.load(open('output/papers_data.json')); print(len(data))" 2>/dev/null || echo "0")
          echo "papers-found=$PAPER_COUNT" >> $GITHUB_OUTPUT
          echo "Found $PAPER_COUNT papers for analysis"
        else
          echo "papers-found=0" >> $GITHUB_OUTPUT
          echo "No papers found"
        fi

    - name: Upload collected data
      if: steps.data-collection.outputs.papers-found > 0
      uses: actions/upload-artifact@v4
      with:
        name: collected-data
        path: |
          output/papers_data.json
          output/analysis_prompts.json

  analyze_papers:
    needs: collect_data
    runs-on: ubuntu-latest
    if: needs.collect_data.outputs.papers-found > 0

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        ssh-key: ${{secrets.PROD_BOT_KEY}}

    - name: Download collected data
      uses: actions/download-artifact@v4
      with:
        name: collected-data
        path: output/

    - name: Analyze papers individually with Gemini
      run: |
        # Process each paper individually (original approach)
        python << 'EOF'
        import json
        import os

        # Load papers data
        with open('output/papers_data.json', 'r') as f:
            papers = json.load(f)

        print(f"Processing {len(papers)} papers individually...")

        # Create individual results array
        all_results = []

        for i, paper in enumerate(papers):
            print(f"Preparing paper {i+1}/{len(papers)}: {paper['title'][:50]}...")
            
            # Create individual paper file for this analysis
            individual_paper = {
                "title": paper["title"],
                "abstract": paper.get("abstract", ""),
                "combined_content": paper.get("combined_content", "")[:2000],  # Limit content size
                "arxiv_url": paper["arxiv_url"]
            }
            
            with open(f'paper_{i+1}.json', 'w') as f:
                json.dump(individual_paper, f, indent=2)
            
            print(f"Created paper_{i+1}.json for individual analysis")

        print("All papers prepared for individual analysis")
        EOF

    - name: Analyze Paper 1
      id: analyze-1
      if: needs.collect_data.outputs.papers-found >= 1
      uses: 'google-github-actions/run-gemini-cli@v0'
      with:
        gemini_api_key: '${{ secrets.GEMINI_API_KEY }}'
        prompt: |
          Analyze this physics research paper and answer the following questions. Respond with a JSON object with the exact question text as keys.

          Questions:
          1. "What is the main physics phenomenon studied by this paper"
          2. "Is this work related to dark matter searches? If yes, how?"
          3. "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?"
          4. "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper"

          Response format:
          {
            "What is the main physics phenomenon studied by this paper": "Your answer here",
            "Is this work related to dark matter searches? If yes, how?": "Your answer here",
            "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?": "Your answer here",
            "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper": "Your answer here"
          }

          Paper to analyze:
          $(cat paper_1.json)

    - name: Analyze Paper 2
      id: analyze-2
      if: needs.collect_data.outputs.papers-found >= 2
      uses: 'google-github-actions/run-gemini-cli@v0'
      with:
        gemini_api_key: '${{ secrets.GEMINI_API_KEY }}'
        prompt: |
          Analyze this physics research paper and answer the following questions. Respond with a JSON object with the exact question text as keys.

          Questions:
          1. "What is the main physics phenomenon studied by this paper"
          2. "Is this work related to dark matter searches? If yes, how?"
          3. "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?"
          4. "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper"

          Response format:
          {
            "What is the main physics phenomenon studied by this paper": "Your answer here",
            "Is this work related to dark matter searches? If yes, how?": "Your answer here",
            "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?": "Your answer here",
            "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper": "Your answer here"
          }

          Paper to analyze:
          $(cat paper_2.json)

    - name: Analyze Paper 3
      id: analyze-3
      if: needs.collect_data.outputs.papers-found >= 3
      uses: 'google-github-actions/run-gemini-cli@v0'
      with:
        gemini_api_key: '${{ secrets.GEMINI_API_KEY }}'
        prompt: |
          Analyze this physics research paper and answer the following questions. Respond with a JSON object with the exact question text as keys.

          Questions:
          1. "What is the main physics phenomenon studied by this paper"
          2. "Is this work related to dark matter searches? If yes, how?"
          3. "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?"
          4. "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper"

          Response format:
          {
            "What is the main physics phenomenon studied by this paper": "Your answer here",
            "Is this work related to dark matter searches? If yes, how?": "Your answer here",
            "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?": "Your answer here",
            "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper": "Your answer here"
          }

          Paper to analyze:
          $(cat paper_3.json)

    - name: Analyze Paper 4
      id: analyze-4
      if: needs.collect_data.outputs.papers-found >= 4
      uses: 'google-github-actions/run-gemini-cli@v0'
      with:
        gemini_api_key: '${{ secrets.GEMINI_API_KEY }}'
        prompt: |
          Analyze this physics research paper and answer the following questions. Respond with a JSON object with the exact question text as keys.

          Questions:
          1. "What is the main physics phenomenon studied by this paper"
          2. "Is this work related to dark matter searches? If yes, how?"
          3. "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?"
          4. "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper"

          Response format:
          {
            "What is the main physics phenomenon studied by this paper": "Your answer here",
            "Is this work related to dark matter searches? If yes, how?": "Your answer here",
            "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?": "Your answer here",
            "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper": "Your answer here"
          }

          Paper to analyze:
          $(cat paper_4.json)

    - name: Analyze Paper 5
      id: analyze-5
      if: needs.collect_data.outputs.papers-found >= 5
      uses: 'google-github-actions/run-gemini-cli@v0'
      with:
        gemini_api_key: '${{ secrets.GEMINI_API_KEY }}'
        prompt: |
          Analyze this physics research paper and answer the following questions. Respond with a JSON object with the exact question text as keys.

          Questions:
          1. "What is the main physics phenomenon studied by this paper"
          2. "Is this work related to dark matter searches? If yes, how?"
          3. "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?"
          4. "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper"

          Response format:
          {
            "What is the main physics phenomenon studied by this paper": "Your answer here",
            "Is this work related to dark matter searches? If yes, how?": "Your answer here",
            "Does this paper present experimental results? If yes, what is the name of the experimental apparatus?": "Your answer here",
            "Does this paper use ML techniques for dark matter searches? And if yes, list the main ML techniques used in this paper": "Your answer here"
          }

          Paper to analyze:
          $(cat paper_5.json)

    - name: Combine individual results
      run: |
        # Combine all individual analysis results
        python << 'EOF'
        import json
        import os

        # Load papers count
        with open('output/papers_data.json', 'r') as f:
            papers_count = len(json.load(f))

        print(f"Combining results for {papers_count} papers")

        # Collect individual results
        results = []
        for i in range(1, papers_count + 1):
            result_var = f"steps.analyze-{i}.outputs.summary"
            print(f"Processing result {i}")
            
            # Get the result from environment or create error result
            if i == 1:
                result = '''${{ steps.analyze-1.outputs.summary }}'''
            elif i == 2:
                result = '''${{ steps.analyze-2.outputs.summary }}'''
            elif i == 3:
                result = '''${{ steps.analyze-3.outputs.summary }}'''
            elif i == 4:
                result = '''${{ steps.analyze-4.outputs.summary }}'''
            elif i == 5:
                result = '''${{ steps.analyze-5.outputs.summary }}'''
            else:
                result = '{"error": "No analysis performed"}'
            
            if not result or result.strip() == '':
                result = '{"error": "Empty LLM response"}'
            
            results.append(result)
            print(f"Added result {i}: {result[:100]}...")

        # Save combined results
        with open('output/llm_results.txt', 'w') as f:
            f.write("---PAPER---".join(results))

        print(f"Saved combined results for {len(results)} papers")
        
        # Debug output
        print("=== Combined Results Preview ===")
        with open('output/llm_results.txt', 'r') as f:
            content = f.read()
            print(content[:500] + "..." if len(content) > 500 else content)
        print("=== End Preview ===")
        EOF

    - name: Upload analysis results
      uses: actions/upload-artifact@v4
      with:
        name: analysis-results
        path: |
          output/papers_data.json
          output/analysis_prompts.json
          output/llm_results.txt

  process_results:
    needs: [collect_data, analyze_papers]
    runs-on: ubuntu-latest
    if: needs.collect_data.outputs.papers-found > 0

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        ssh-key: ${{secrets.PROD_BOT_KEY}}

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install uv and dependencies
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        export PATH="$HOME/.local/bin:$PATH"
        uv venv
        source .venv/bin/activate
        uv pip install -e .

    - name: Download analysis results
      uses: actions/download-artifact@v4
      with:
        name: analysis-results
        path: output/

    - name: Process results and generate markdown
      run: |
        export PATH="$HOME/.local/bin:$PATH"
        source .venv/bin/activate
        
        # Run result processing phase
        uv run ciphr-hybrid --mode process --output_dir output --output_filename hepex.md --verbose

    - name: Check for ML4DM papers and prepare Mattermost notification
      id: ml4dm-check
      run: |
        export PATH="$HOME/.local/bin:$PATH"
        source .venv/bin/activate
        
        # Run ML4DM analysis
        uv run python << 'EOF'
        import json
        import os
        import sys
        from ciphr.src.mattermost_notifier import check_ml4dm_papers, MattermostNotifier

        # Load papers data
        with open('output/papers_data.json', 'r') as f:
            papers_data = json.load(f)

        # Load LLM results
        with open('output/llm_results.txt', 'r') as f:
            content = f.read().strip()

        # Parse LLM results (same logic as in ciphr_hybrid.py)
        PAPER_SEPARATOR = "---PAPER---"
        if PAPER_SEPARATOR in content:
            llm_results = content.split(PAPER_SEPARATOR)
            llm_results = [result.strip() for result in llm_results if result.strip()]
        else:
            llm_results = [content]

        # Ensure we have the right number of results
        if len(llm_results) < len(papers_data):
            while len(llm_results) < len(papers_data):
                llm_results.append('{"error": "No LLM result available"}')
        elif len(llm_results) > len(papers_data):
            llm_results = llm_results[:len(papers_data)]

        print(f"Analyzing {len(papers_data)} papers for ML4DM usage...")

        # Check for ML4DM papers
        ml4dm_papers = check_ml4dm_papers(papers_data, llm_results)

        # Save results
        with open('output/ml4dm_papers.json', 'w') as f:
            json.dump(ml4dm_papers, f, indent=2)

        # Set output for next step
        has_ml4dm = len(ml4dm_papers) > 0
        print(f"Found {len(ml4dm_papers)} ML4DM papers")
        
        # Write to GitHub Actions output
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f"has-ml4dm-papers={'true' if has_ml4dm else 'false'}\n")
            f.write(f"ml4dm-count={len(ml4dm_papers)}\n")

        if has_ml4dm:
            print("ML4DM papers found - will post to Mattermost")
        else:
            print("No ML4DM papers found - skipping Mattermost notification")
        EOF

    - name: Post to Mattermost if ML4DM papers found
      if: steps.ml4dm-check.outputs.has-ml4dm-papers == 'true'
      env:
        MM_WEBHOOK_URL: ${{ secrets.MM_WEBHOOK_URL }}
      run: |
        export PATH="$HOME/.local/bin:$PATH"
        source .venv/bin/activate
        
        uv run python << 'EOF'
        import json
        import os
        import sys
        from ciphr.src.mattermost_notifier import MattermostNotifier

        # Get webhook URL from environment
        webhook_url = os.getenv('MM_WEBHOOK_URL')
        if not webhook_url:
            print("ERROR: MM_WEBHOOK_URL not found in environment")
            sys.exit(1)

        # Load ML4DM papers
        with open('output/ml4dm_papers.json', 'r') as f:
            ml4dm_papers = json.load(f)

        if not ml4dm_papers:
            print("No ML4DM papers to post")
            sys.exit(0)

        # Create repository link to the output file
        repo_link = "https://github.com/${{ github.repository }}/blob/${{ github.ref_name }}/output/hepex.md"

        # Initialize notifier and post
        notifier = MattermostNotifier(webhook_url)
        success = notifier.post_ml4dm_findings(ml4dm_papers, repo_link)

        if success:
            print(f"Successfully posted {len(ml4dm_papers)} ML4DM papers to Mattermost")
        else:
            print("Failed to post to Mattermost")
            sys.exit(1)
        EOF

    - name: Upload final insights
      uses: actions/upload-artifact@v4
      with:
        name: hep-ex-insights
        path: output/hepex*.md

    - name: Commit and push changes (if any)
      run: |
        git config user.name github-actions
        git config user.email github-actions@github.com
        # Only commit the final markdown file, not the intermediate JSON/txt files
        git add --force output/hepex*.md
        git commit -m "Update research insights table (hybrid approach)" || echo "No changes to commit"
        git push origin HEAD
